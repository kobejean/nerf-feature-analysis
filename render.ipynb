{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccl/anaconda3/envs/NeRF/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import importlib.util\n",
    "import tqdm\n",
    "\n",
    "from torch import Tensor\n",
    "import nerfacc\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "from nerfacc.estimators.prop_net import (\n",
    "    PropNetEstimator,\n",
    "    get_proposal_requires_grad_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = \"output/test9\"\n",
    "root_fp = \"/media/ccl/Data/Datasets/NeRF/aizu-student-hall/output/processed\"\n",
    "test_chunk_size=8192\n",
    "\n",
    "# Create a module spec\n",
    "spec = importlib.util.spec_from_file_location('ngp_appearance', f'{exp_dir}/ngp_appearance.py')\n",
    "ngp_appearance = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(ngp_appearance)\n",
    "NGPDensityField = ngp_appearance.NGPDensityField\n",
    "NGPRadianceField = ngp_appearance.NGPRadianceField\n",
    "\n",
    "# spec = importlib.util.spec_from_file_location('nerf_colmap', f'{exp_dir}/nerf_colmap.py')\n",
    "# nerf_colmap = importlib.util.module_from_spec(spec)\n",
    "# spec.loader.exec_module(nerf_colmap)\n",
    "# SubjectLoader = nerf_colmap.SubjectLoader\n",
    "from datasets.nerf_colmap import SubjectLoader\n",
    "\n",
    "device = \"cuda:0\"\n",
    "# scene parameters\n",
    "unbounded = True\n",
    "aabb = torch.tensor([-1.0, -1.0, -1.0, 1.0, 1.0, 1.0], device=device)\n",
    "near_plane = 0.2  # TODO: Try 0.02\n",
    "far_plane = 1e3\n",
    "# dataset parameters\n",
    "train_dataset_kwargs = {\"color_bkgd_aug\": \"random\", \"factor\": 2}\n",
    "test_dataset_kwargs = {\"factor\": 4}\n",
    "# model parameters\n",
    "proposal_networks = [\n",
    "    NGPDensityField(\n",
    "        aabb=aabb,\n",
    "        unbounded=unbounded,\n",
    "        n_levels=5,\n",
    "        max_resolution=128,\n",
    "    ).to(device),\n",
    "    NGPDensityField(\n",
    "        aabb=aabb,\n",
    "        unbounded=unbounded,\n",
    "        n_levels=5,\n",
    "        max_resolution=256,\n",
    "    ).to(device),\n",
    "]\n",
    "\n",
    "estimator = PropNetEstimator().to(device)\n",
    "# radiance_field = NGPRadianceField(aabb=aabb, unbounded=unbounded, max_resolution=4096*2, n_levels=16, log2_hashmap_size=17).to(device)\n",
    "# radiance_field = NGPRadianceField(aabb=aabb, unbounded=unbounded, max_resolution=4096*4, n_levels=18, log2_hashmap_size=19).to(device)\n",
    "radiance_field = NGPRadianceField(aabb=aabb, unbounded=unbounded, max_resolution=4096*8, n_levels=19, log2_hashmap_size=20).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['aabb', 'mlp_base.params'])\n",
      "odict_keys(['aabb', 'mlp_base.params'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PropNetEstimator()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radiance_field.load_state_dict(torch.load(os.path.join(exp_dir, 'radiance_field.pth')))\n",
    "# estimator.load_state_dict(torch.load(os.path.join(exp_dir, 'estimator.pth')))\n",
    "\n",
    "for i, net in enumerate(proposal_networks):\n",
    "    state_dict = torch.load(os.path.join(exp_dir, f'proposal_network_{i}.pth'))\n",
    "    print(state_dict.keys())\n",
    "    net.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "radiance_field.eval()\n",
    "for p in proposal_networks:\n",
    "    p.eval()\n",
    "estimator.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "loading images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 616/616 [00:01<00:00, 385.82it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets.utils import Rays\n",
    "from utils import (\n",
    "    render_image_with_propnet,\n",
    ")\n",
    "from datasets.nerf_colmap import _load_colmap, similarity_from_cameras\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# render parameters\n",
    "num_samples = 64\n",
    "num_samples_per_prop = [256, 96]\n",
    "sampling_type = \"lindisp\"\n",
    "opaque_bkgd = True\n",
    "factor = 4\n",
    "\n",
    "images, camtoworlds, K, split_indices = _load_colmap(\n",
    "    root_fp, 0, factor\n",
    ")\n",
    "# normalize the scene\n",
    "T, sscale = similarity_from_cameras(\n",
    "    camtoworlds, strict_scaling=True\n",
    ")\n",
    "camtoworlds = np.einsum(\"nij, ki -> nkj\", camtoworlds, T)\n",
    "camtoworlds[:, :3, 3] *= sscale\n",
    "\n",
    "images = torch.from_numpy(images).to(torch.uint8).to(device)\n",
    "camtoworlds = (\n",
    "    torch.from_numpy(camtoworlds).to(torch.float32).to(device)\n",
    ")\n",
    "K = torch.tensor(K).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "loading images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 616/616 [00:01<00:00, 411.02it/s]\n",
      " 75%|███████▌  | 58/77 [00:34<00:11,  1.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/NeRF/lib/python3.10/site-packages/PIL/ImageFile.py:503\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 503\u001b[0m     fh \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mfileno()\n\u001b[1;32m    504\u001b[0m     fp\u001b[39m.\u001b[39mflush()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m\n\u001b[1;32m     36\u001b[0m os\u001b[39m.\u001b[39mmakedirs(renders_dir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m imageio\u001b[39m.\u001b[39mimwrite(\n\u001b[1;32m     39\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(renders_dir, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrgb_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m:\u001b[39;00m\u001b[39m08\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_render.png\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     40\u001b[0m     (rgb\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy() \u001b[39m*\u001b[39m \u001b[39m255\u001b[39m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8),\n\u001b[1;32m     41\u001b[0m )\n\u001b[0;32m---> 42\u001b[0m imageio\u001b[39m.\u001b[39;49mimwrite(\n\u001b[1;32m     43\u001b[0m     os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(renders_dir, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrgb_\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m:\u001b[39;49;00m\u001b[39m08\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m_ground_truth.png\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     44\u001b[0m     (pixels\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mnumpy() \u001b[39m*\u001b[39;49m \u001b[39m255\u001b[39;49m)\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49muint8),\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     46\u001b[0m imageio\u001b[39m.\u001b[39mimwrite(\n\u001b[1;32m     47\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(renders_dir, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrgb_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m:\u001b[39;00m\u001b[39m08\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_error.png\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     48\u001b[0m     (\n\u001b[1;32m     49\u001b[0m         (rgb \u001b[39m-\u001b[39m pixels)\u001b[39m.\u001b[39mnorm(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy() \u001b[39m*\u001b[39m \u001b[39m255\u001b[39m\n\u001b[1;32m     50\u001b[0m     )\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8),\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     52\u001b[0m vis_depth \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlog(depth)\n",
      "File \u001b[0;32m~/anaconda3/envs/NeRF/lib/python3.10/site-packages/imageio/v2.py:264\u001b[0m, in \u001b[0;36mimwrite\u001b[0;34m(uri, im, format, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m imopen_args[\u001b[39m\"\u001b[39m\u001b[39mlegacy_mode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39mwith\u001b[39;00m imopen(uri, \u001b[39m\"\u001b[39m\u001b[39mwi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mimopen_args) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m file\u001b[39m.\u001b[39;49mwrite(im, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/NeRF/lib/python3.10/site-packages/imageio/core/legacy_plugin_wrapper.py:253\u001b[0m, in \u001b[0;36mLegacyPlugin.write\u001b[0;34m(self, ndimage, is_batch, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(image\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mnumber) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(\n\u001b[1;32m    247\u001b[0m             image\u001b[39m.\u001b[39mdtype, \u001b[39mbool\u001b[39m\n\u001b[1;32m    248\u001b[0m         ):\n\u001b[1;32m    249\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    250\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAll images have to be numeric, and not `\u001b[39m\u001b[39m{\u001b[39;00mimage\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m             )\n\u001b[0;32m--> 253\u001b[0m         writer\u001b[39m.\u001b[39;49mappend_data(image, metadata)\n\u001b[1;32m    255\u001b[0m \u001b[39mreturn\u001b[39;00m writer\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/NeRF/lib/python3.10/site-packages/imageio/core/format.py:590\u001b[0m, in \u001b[0;36mFormat.Writer.append_data\u001b[0;34m(self, im, meta)\u001b[0m\n\u001b[1;32m    588\u001b[0m im \u001b[39m=\u001b[39m asarray(im)\n\u001b[1;32m    589\u001b[0m \u001b[39m# Call\u001b[39;00m\n\u001b[0;32m--> 590\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_append_data(im, total_meta)\n",
      "File \u001b[0;32m~/anaconda3/envs/NeRF/lib/python3.10/site-packages/imageio/plugins/pillow_legacy.py:458\u001b[0m, in \u001b[0;36mPNGFormat.Writer._append_data\u001b[0;34m(self, im, meta)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     im \u001b[39m=\u001b[39m image_as_uint(im, bitdepth\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[0;32m--> 458\u001b[0m PillowFormat\u001b[39m.\u001b[39;49mWriter\u001b[39m.\u001b[39;49m_append_data(\u001b[39mself\u001b[39;49m, im, meta)\n",
      "File \u001b[0;32m~/anaconda3/envs/NeRF/lib/python3.10/site-packages/imageio/plugins/pillow_legacy.py:380\u001b[0m, in \u001b[0;36mPillowFormat.Writer._append_data\u001b[0;34m(self, im, meta)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mbits\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_meta:\n\u001b[1;32m    379\u001b[0m     img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mquantize()  \u001b[39m# Make it a P image, so bits arg is used\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m img\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat\u001b[39m.\u001b[39;49mplugin_id, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_meta)\n\u001b[1;32m    381\u001b[0m save_pillow_close(img)\n",
      "File \u001b[0;32m~/anaconda3/envs/NeRF/lib/python3.10/site-packages/PIL/Image.py:2353\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mw+b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2353\u001b[0m     save_handler(\u001b[39mself\u001b[39;49m, fp, filename)\n\u001b[1;32m   2354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   2355\u001b[0m     \u001b[39mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m~/anaconda3/envs/NeRF/lib/python3.10/site-packages/PIL/PngImagePlugin.py:1397\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1395\u001b[0m     _write_multiple_frames(im, fp, chunk, rawmode, default_image, append_images)\n\u001b[1;32m   1396\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1397\u001b[0m     ImageFile\u001b[39m.\u001b[39;49m_save(im, _idat(fp, chunk), [(\u001b[39m\"\u001b[39;49m\u001b[39mzip\u001b[39;49m\u001b[39m\"\u001b[39;49m, (\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m) \u001b[39m+\u001b[39;49m im\u001b[39m.\u001b[39;49msize, \u001b[39m0\u001b[39;49m, rawmode)])\n\u001b[1;32m   1399\u001b[0m \u001b[39mif\u001b[39;00m info:\n\u001b[1;32m   1400\u001b[0m     \u001b[39mfor\u001b[39;00m info_chunk \u001b[39min\u001b[39;00m info\u001b[39m.\u001b[39mchunks:\n",
      "File \u001b[0;32m~/anaconda3/envs/NeRF/lib/python3.10/site-packages/PIL/ImageFile.py:507\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    505\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[1;32m    506\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, io\u001b[39m.\u001b[39mUnsupportedOperation) \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m--> 507\u001b[0m     _encode_tile(im, fp, tile, bufsize, \u001b[39mNone\u001b[39;49;00m, exc)\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(fp, \u001b[39m\"\u001b[39m\u001b[39mflush\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    509\u001b[0m     fp\u001b[39m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/anaconda3/envs/NeRF/lib/python3.10/site-packages/PIL/ImageFile.py:526\u001b[0m, in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39mif\u001b[39;00m exc:\n\u001b[1;32m    524\u001b[0m     \u001b[39m# compress to Python file-compatible object\u001b[39;00m\n\u001b[1;32m    525\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 526\u001b[0m         l, s, d \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39;49mencode(bufsize)\n\u001b[1;32m    527\u001b[0m         fp\u001b[39m.\u001b[39mwrite(d)\n\u001b[1;32m    528\u001b[0m         \u001b[39mif\u001b[39;00m s:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_dataset = SubjectLoader(\n",
    "    subject_id=0,\n",
    "    root_fp=root_fp,\n",
    "    split=\"test\",\n",
    "    num_rays=None,\n",
    "    device=device,\n",
    "    **test_dataset_kwargs,\n",
    ")\n",
    "with torch.no_grad():\n",
    "    for i in tqdm.tqdm(range(len(test_dataset))):\n",
    "        data = test_dataset[i]\n",
    "        render_bkgd = data[\"color_bkgd\"]\n",
    "        rays = data[\"rays\"]\n",
    "        pixels = data[\"pixels\"]\n",
    "        img = data[\"img\"]\n",
    "\n",
    "        # rendering\n",
    "        rgb, acc, depth, _, = render_image_with_propnet(\n",
    "            radiance_field,\n",
    "            proposal_networks,\n",
    "            estimator,\n",
    "            rays,\n",
    "            # rendering options\n",
    "            num_samples=num_samples,\n",
    "            num_samples_per_prop=num_samples_per_prop,\n",
    "            near_plane=near_plane,\n",
    "            far_plane=far_plane,\n",
    "            sampling_type=sampling_type,\n",
    "            opaque_bkgd=opaque_bkgd,\n",
    "            render_bkgd=render_bkgd,\n",
    "            # test options\n",
    "            test_chunk_size=test_chunk_size,\n",
    "            img=img,\n",
    "        )\n",
    "        renders_dir = os.path.join(exp_dir, \"renders\")\n",
    "        os.makedirs(renders_dir, exist_ok=True)\n",
    "\n",
    "        imageio.imwrite(\n",
    "            os.path.join(renders_dir, f\"rgb_{i:08}_render.png\"),\n",
    "            (rgb.cpu().numpy() * 255).astype(np.uint8),\n",
    "        )\n",
    "        imageio.imwrite(\n",
    "            os.path.join(renders_dir, f\"rgb_{i:08}_ground_truth.png\"),\n",
    "            (pixels.cpu().numpy() * 255).astype(np.uint8),\n",
    "        )\n",
    "        imageio.imwrite(\n",
    "            os.path.join(renders_dir, f\"rgb_{i:08}_error.png\"),\n",
    "            (\n",
    "                (rgb - pixels).norm(dim=-1).cpu().numpy() * 255\n",
    "            ).astype(np.uint8),\n",
    "        )\n",
    "        vis_depth = torch.log(depth)\n",
    "        vis_depth -= torch.min(vis_depth)\n",
    "        vis_depth /= torch.max(vis_depth)\n",
    "        imageio.imwrite(\n",
    "            os.path.join(renders_dir, f\"rgb_{i:08}_depth.png\"),\n",
    "            (\n",
    "                vis_depth.cpu().numpy() * 255\n",
    "            ).astype(np.uint8),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index in range(50):\n",
    "#     image_id = [index]\n",
    "#     height, width = images.shape[1:3]\n",
    "\n",
    "#     \n",
    "#     color_bkgd = torch.ones(3, device=images.device)\n",
    "\n",
    "#     x, y = torch.meshgrid(\n",
    "#         torch.arange(width, device=images.device),\n",
    "#         torch.arange(height, device=images.device),\n",
    "#         indexing=\"xy\",\n",
    "#     )\n",
    "#     x = x.flatten()\n",
    "#     y = y.flatten()\n",
    "\n",
    "#     c2w = camtoworlds[image_id]  # (num_rays, 3, 4)\n",
    "#     camera_dirs = F.pad(\n",
    "#         torch.stack(\n",
    "#             [\n",
    "#                 (x - K[0, 2] + 0.5) / K[0, 0],\n",
    "#                 (y - K[1, 2] + 0.5)\n",
    "#                 / K[1, 1]\n",
    "#                 * (1.0),\n",
    "#             ],\n",
    "#             dim=-1,\n",
    "#         ),\n",
    "#         (0, 1),\n",
    "#         value=(1.0),\n",
    "#     ) \n",
    "#     directions = (camera_dirs[:, None, :] * c2w[:, :3, :3]).sum(dim=-1)\n",
    "#     origins = torch.broadcast_to(c2w[:, :3, -1], directions.shape)\n",
    "#     viewdirs = directions / torch.linalg.norm(directions, dim=-1, keepdims=True)\n",
    "#     origins = torch.reshape(origins, (height, width, 3))\n",
    "#     viewdirs = torch.reshape(viewdirs, (height, width, 3))\n",
    "\n",
    "\n",
    "#     rays = Rays(origins=origins, viewdirs=viewdirs)\n",
    "\n",
    "#     img = torch.transpose(images[index], 0, 2)\n",
    "#     img = torch.transpose(img, 1, 2)\n",
    "#     img = (img / 255.0).unsqueeze(0).cuda()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         rgb, acc, depth, _, = render_image_with_propnet(\n",
    "#             radiance_field,\n",
    "#             proposal_networks,\n",
    "#             estimator,\n",
    "#             rays,\n",
    "#             # rendering options\n",
    "#             num_samples=num_samples,\n",
    "#             num_samples_per_prop=num_samples_per_prop,\n",
    "#             near_plane=near_plane,\n",
    "#             far_plane=far_plane,\n",
    "#             sampling_type=sampling_type,\n",
    "#             opaque_bkgd=opaque_bkgd,\n",
    "#             render_bkgd=color_bkgd,\n",
    "#             # test options\n",
    "#             test_chunk_size=test_chunk_size,\n",
    "#             img=img,\n",
    "#         )\n",
    "#         renders_dir = os.path.join(exp_dir, \"renders\")\n",
    "#         os.makedirs(renders_dir, exist_ok=True)\n",
    "#         imageio.imwrite(\n",
    "#             os.path.join(renders_dir, f\"rgb_{index:08}_render.png\"),\n",
    "#             (rgb.cpu().numpy() * 255).astype(np.uint8),\n",
    "#         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeRF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
